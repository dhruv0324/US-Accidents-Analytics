{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fea03882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file in parallel using 14 processes...\n",
      "File size: 0.79 GB, Columns: 18\n",
      "Processing chunks in parallel...\n",
      "Parallel reading completed in 14.81s. Combining results...\n",
      "Combining completed in 0.43s\n",
      "âœ“ Total time: 15.24s - Loaded 6,985,065 rows\n",
      "Loaded dataset: (6985065, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID  | Severity | Start_Time          | Start_Lat         | Start_Lng          | Distance(mi) | City         | State | Temperature(F) | Visibility(mi) | Wind_Speed(mph) | Precipitation(in) | Weather_Condition | Sunrise_Sunset | Year | Month | DayOfWeek | Hour\n",
       "----+----------+---------------------+-------------------+--------------------+--------------+--------------+-------+----------------+----------------+-----------------+-------------------+-------------------+----------------+------+-------+-----------+-----\n",
       "A-2 | 2        | 2016-02-08 06:07:59 | 39.92805900000001 | -82.831184         | 0.01         | Reynoldsburg | OH    | 37.9           | 10.0           | None            | 0.0               | Light Rain        | Night          | 2016 | 2     | Monday    | 6   \n",
       "A-3 | 2        | 2016-02-08 06:49:27 | 39.063148         | -84.032608         | 0.01         | Williamsburg | OH    | 36.0           | 10.0           | 3.5             | None              | Overcast          | Night          | 2016 | 2     | Monday    | 6   \n",
       "A-4 | 3        | 2016-02-08 07:23:34 | 39.747753         | -84.20558199999998 | 0.01         | Dayton       | OH    | 35.1           | 9.0            | 4.6             | None              | Mostly Cloudy     | Night          | 2016 | 2     | Monday    | 7   \n",
       "\n",
       "[3 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "APP_DIR = Path().resolve()\n",
    "if str(APP_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(APP_DIR))\n",
    "\n",
    "from functions import DataFrame, read_csv_parallel, describe, read_csv\n",
    "\n",
    "# Load dataset\n",
    "DATA_DIR = APP_DIR.parent / \"data\"\n",
    "df = read_csv_parallel(str(DATA_DIR / \"us_accidents_clean.csv\"), skip_type_inference=False, verbose=True)\n",
    "print(f\"Loaded dataset: {df.shape()}\")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5723c329",
   "metadata": {},
   "source": [
    "The following part is just for demonstration of the difference between using parallel (chunking) processes for loading vs normal read_csv function.\n",
    "read_csv takes a minute more to load compared to read_csv_parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470aee10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file: /Users/dhruvsandu/USC/551-Data Management/Project/data/us_accidents_clean.csv\n",
      "Columns: 18\n",
      "  Completed! Loaded 6,985,002 rows.                    \n"
     ]
    }
   ],
   "source": [
    "df_test = read_csv(str(DATA_DIR / \"us_accidents_clean.csv\"), skip_type_inference=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c462c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6985065, 18)\n",
      "\n",
      "First 3 rows:\n",
      "ID  | Severity | Start_Time          | Start_Lat         | Start_Lng          | Distance(mi) | City         | State | Temperature(F) | Visibility(mi) | Wind_Speed(mph) | Precipitation(in) | Weather_Condition | Sunrise_Sunset | Year | Month | DayOfWeek | Hour\n",
      "----+----------+---------------------+-------------------+--------------------+--------------+--------------+-------+----------------+----------------+-----------------+-------------------+-------------------+----------------+------+-------+-----------+-----\n",
      "A-2 | 2        | 2016-02-08 06:07:59 | 39.92805900000001 | -82.831184         | 0.01         | Reynoldsburg | OH    | 37.9           | 10.0           | None            | 0.0               | Light Rain        | Night          | 2016 | 2     | Monday    | 6   \n",
      "A-3 | 2        | 2016-02-08 06:49:27 | 39.063148         | -84.032608         | 0.01         | Williamsburg | OH    | 36.0           | 10.0           | 3.5             | None              | Overcast          | Night          | 2016 | 2     | Monday    | 6   \n",
      "A-4 | 3        | 2016-02-08 07:23:34 | 39.747753         | -84.20558199999998 | 0.01         | Dayton       | OH    | 35.1           | 9.0            | 4.6             | None              | Mostly Cloudy     | Night          | 2016 | 2     | Monday    | 7   \n",
      "\n",
      "[3 rows x 18 columns]\n",
      "\n",
      "Last 3 rows:\n",
      "ID        | Severity | Start_Time          | Start_Lat          | Start_Lng  | Distance(mi) | City        | State | Temperature(F) | Visibility(mi) | Wind_Speed(mph) | Precipitation(in) | Weather_Condition | Sunrise_Sunset | Year | Month | DayOfWeek | Hour\n",
      "----------+----------+---------------------+--------------------+------------+--------------+-------------+-------+----------------+----------------+-----------------+-------------------+-------------------+----------------+------+-------+-----------+-----\n",
      "A-7777759 | 2        | 2019-08-23 19:00:21 | 33.77545           | -117.84779 | 0.56         | Orange      | CA    | 73.0           | 10.0           | 10.0            | 0.0               | Partly Cloudy     | Day            | 2019 | 8     | Friday    | 19  \n",
      "A-7777760 | 2        | 2019-08-23 19:00:21 | 33.992459999999994 | -118.40302 | 0.77         | Culver City | CA    | 71.0           | 10.0           | 8.0             | 0.0               | Fair              | Day            | 2019 | 8     | Friday    | 19  \n",
      "A-7777761 | 2        | 2019-08-23 18:52:06 | 34.13393           | -117.23092 | 0.54         | Highland    | CA    | 79.0           | 7.0            | 7.0             | 0.0               | Fair              | Day            | 2019 | 8     | Friday    | 18  \n",
      "\n",
      "[3 rows x 18 columns]\n",
      "\n",
      "Copy test:\n",
      "Original: 6985065 rows, Copy: 6985065 rows\n"
     ]
    }
   ],
   "source": [
    "# Basic operations: head, tail, shape, copy\n",
    "print(\"Shape:\", df.shape())\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(df.head(3))\n",
    "print(\"\\nLast 3 rows:\")\n",
    "print(df.tail(3))\n",
    "print(\"\\nCopy test:\")\n",
    "df_copy = df.copy()\n",
    "print(f\"Original: {len(df)} rows, Copy: {len(df_copy)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcd7008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California accidents: 1567144 rows\n",
      "High severity (>=4) accidents: 184709 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID     | Severity | Start_Time          | Start_Lat | Start_Lng   | Distance(mi) | City      | State | Temperature(F) | Visibility(mi) | Wind_Speed(mph) | Precipitation(in) | Weather_Condition | Sunrise_Sunset | Year | Month | DayOfWeek | Hour\n",
       "-------+----------+---------------------+-----------+-------------+--------------+-----------+-------+----------------+----------------+-----------------+-------------------+-------------------+----------------+------+-------+-----------+-----\n",
       "A-620  | 4        | 2016-03-11 13:18:48 | 39.917412 | -83.014236  | 0.01         | Columbus  | OH    | 51.8           | 10.0           | 5.8             | None              | Clear             | Day            | 2016 | 3     | Friday    | 13  \n",
       "A-1198 | 4        | 2016-06-24 22:28:49 | 37.321117 | -121.899887 | 0.0          | San Jose  | CA    | 66.0           | 10.0           | 5.8             | None              | Clear             | Night          | 2016 | 6     | Friday    | 22  \n",
       "A-1902 | 4        | 2016-07-01 14:09:13 | 37.630623 | -122.435043 | 0.0          | San Bruno | CA    | 68.0           | 10.0           | 15.0            | None              | Partly Cloudy     | Day            | 2016 | 7     | Friday    | 14  \n",
       "\n",
       "[3 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter operations\n",
    "# Filter by value\n",
    "ca_accidents = df.filter_by_value(\"State\", \"CA\")\n",
    "print(f\"California accidents: {len(ca_accidents)} rows\")\n",
    "\n",
    "# Filter with condition function\n",
    "high_severity = df.filter(lambda row: row.get(\"Severity\", 0) >= 4)\n",
    "print(f\"High severity (>=4) accidents: {len(high_severity)} rows\")\n",
    "high_severity.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a305df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6985065, 18)\n",
      "Selected columns: ['State', 'City', 'Severity']\n",
      "Shape: (6985065, 3)\n",
      "\n",
      "After dropping lat/lng: (6985065, 16)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape())\n",
    "\n",
    "# Select and drop columns\n",
    "selected = df.select([\"State\", \"City\", \"Severity\"])\n",
    "print(f\"Selected columns: {selected.columns}\")\n",
    "print(f\"Shape: {selected.shape()}\")\n",
    "\n",
    "dropped = df.drop([\"Start_Lat\", \"Start_Lng\"])\n",
    "print(f\"\\nAfter dropping lat/lng: {dropped.shape()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d31a77cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 accidents by severity:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State | City        | Severity | Distance(mi)\n",
       "------+-------------+----------+-------------\n",
       "OH    | Columbus    | 4        | 0.01        \n",
       "CA    | San Jose    | 4        | 0.0         \n",
       "CA    | San Bruno   | 4        | 0.0         \n",
       "CA    | San Jose    | 4        | 0.0         \n",
       "CA    | San Leandro | 4        | 0.0         \n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort operation\n",
    "sorted_df = df.sort(\"Severity\", ascending=False)\n",
    "print(\"Top 5 accidents by severity:\")\n",
    "sorted_df.head(5).select([\"State\", \"City\", \"Severity\", \"Distance(mi)\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11e81096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 6985065\n",
      "Average severity: 2.2292474014200296\n",
      "Max severity: 4\n",
      "Min severity: 1\n",
      "Average distance: 0.4608920217626519\n"
     ]
    }
   ],
   "source": [
    "# Aggregate (single column operations)\n",
    "print(\"Total count:\", df.aggregate(\"Severity\", \"count\"))\n",
    "print(\"Average severity:\", df.aggregate(\"Severity\", \"mean\"))\n",
    "print(\"Max severity:\", df.aggregate(\"Severity\", \"max\"))\n",
    "print(\"Min severity:\", df.aggregate(\"Severity\", \"min\"))\n",
    "print(\"Average distance:\", df.aggregate(\"Distance(mi)\", \"mean\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bf5ed66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 states by total accidents:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State | total_accidents\n",
       "------+----------------\n",
       "CA    | 1786142        \n",
       "FL    | 765592         \n",
       "TX    | 631112         \n",
       "SC    | 379375         \n",
       "NY    | 310324         \n",
       "\n",
       "[5 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GroupBy with aggregation\n",
    "state_year = read_csv_parallel(str(DATA_DIR / \"us_accidents_state_year.csv\"), skip_type_inference=False, verbose=False)\n",
    "\n",
    "# Group by State and sum accidents\n",
    "state_totals = state_year.groupby(\"State\").agg({\"total_accidents\": \"sum\"})\n",
    "print(\"Top 5 states by total accidents:\")\n",
    "state_totals.sort(\"total_accidents\", ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c221371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined DataFrames:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State | total_accidents | avg_distance       \n",
       "------+-----------------+--------------------\n",
       "AL    | 95816           | 0.6785714285714287 \n",
       "AR    | 18385           | 0.9087999999999998 \n",
       "AZ    | 153989          | 0.6562068965517242 \n",
       "CA    | 1786142         | 0.34171428571428575\n",
       "CO    | 82828           | 0.8844827586206897 \n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join operation\n",
    "df1 = state_year.groupby(\"State\").agg({\"total_accidents\": \"sum\"}).head(5)\n",
    "df2 = state_year.groupby(\"State\").agg({\"avg_distance\": \"mean\"}).head(5)\n",
    "\n",
    "# Join on State\n",
    "joined = df1.join(df2, on=\"State\", how=\"left\")\n",
    "print(\"Joined DataFrames:\")\n",
    "joined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b2883c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with new column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State | City         | multiplier\n",
       "------+--------------+-----------\n",
       "OH    | Reynoldsburg | 0         \n",
       "OH    | Williamsburg | 10        \n",
       "OH    | Dayton       | 20        \n",
       "OH    | Dayton       | 30        \n",
       "OH    | Westerville  | 40        \n",
       "OH    | Dayton       | 50        \n",
       "OH    | Dayton       | 60        \n",
       "OH    | Dayton       | 70        \n",
       "OH    | Westerville  | 80        \n",
       "OH    | Columbus     | 90        \n",
       "\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column\n",
    "sample = df.head(10)\n",
    "new_values = [i * 10 for i in range(len(sample))]\n",
    "df_with_new_col = sample.add_column(\"multiplier\", new_values)\n",
    "print(\"DataFrame with new column:\")\n",
    "df_with_new_col.select([\"State\", \"City\", \"multiplier\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d7104be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed columns: ['ID', 'Severity', 'Start_Time', 'Start_Lat', 'Start_Lng', 'Distance(mi)', 'city', 'state', 'Temperature(F)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition', 'Sunrise_Sunset', 'Year', 'Month', 'DayOfWeek', 'Hour']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID  | Severity | Start_Time          | Start_Lat         | Start_Lng          | Distance(mi) | city         | state | Temperature(F) | Visibility(mi) | Wind_Speed(mph) | Precipitation(in) | Weather_Condition | Sunrise_Sunset | Year | Month | DayOfWeek | Hour\n",
       "----+----------+---------------------+-------------------+--------------------+--------------+--------------+-------+----------------+----------------+-----------------+-------------------+-------------------+----------------+------+-------+-----------+-----\n",
       "A-2 | 2        | 2016-02-08 06:07:59 | 39.92805900000001 | -82.831184         | 0.01         | Reynoldsburg | OH    | 37.9           | 10.0           | None            | 0.0               | Light Rain        | Night          | 2016 | 2     | Monday    | 6   \n",
       "A-3 | 2        | 2016-02-08 06:49:27 | 39.063148         | -84.032608         | 0.01         | Williamsburg | OH    | 36.0           | 10.0           | 3.5             | None              | Overcast          | Night          | 2016 | 2     | Monday    | 6   \n",
       "A-4 | 3        | 2016-02-08 07:23:34 | 39.747753         | -84.20558199999998 | 0.01         | Dayton       | OH    | 35.1           | 9.0            | 4.6             | None              | Mostly Cloudy     | Night          | 2016 | 2     | Monday    | 7   \n",
       "A-5 | 2        | 2016-02-08 07:39:07 | 39.627781         | -84.188354         | 0.01         | Dayton       | OH    | 36.0           | 6.0            | 3.5             | None              | Mostly Cloudy     | Day            | 2016 | 2     | Monday    | 7   \n",
       "A-6 | 3        | 2016-02-08 07:44:26 | 40.10059          | -82.92519399999998 | 0.01         | Westerville  | OH    | 37.9           | 7.0            | 3.5             | 0.03              | Light Rain        | Day            | 2016 | 2     | Monday    | 7   \n",
       "\n",
       "[5 rows x 18 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns\n",
    "renamed = df.head(5).rename_columns({\"State\": \"state\", \"City\": \"city\"})\n",
    "print(\"Renamed columns:\", renamed.columns)\n",
    "renamed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0df9109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fillna: [None, None, 3]\n",
      "After fillna: [0, 0, 3]\n"
     ]
    }
   ],
   "source": [
    "# Fillna operation\n",
    "sample_df = df.head(10).select([\"State\", \"City\", \"Severity\"])\n",
    "# Simulating missing values\n",
    "sample_df.data[\"Severity\"][0] = None\n",
    "sample_df.data[\"Severity\"][1] = None\n",
    "\n",
    "filled = sample_df.fillna_column(\"Severity\", 0)\n",
    "print(\"Before fillna:\", sample_df.data[\"Severity\"][:3])\n",
    "print(\"After fillna:\", filled.data[\"Severity\"][:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e81e667c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original types:\n",
      "Severity sample: [2, 2, 3]\n",
      "Distance sample: [0.01, 0.01, 0.01]\n",
      "\n",
      "After converting Severity to string:\n",
      "['2', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "# Convert column type\n",
    "sample = df.head(10).select([\"Severity\", \"Distance(mi)\"])\n",
    "print(\"Original types:\")\n",
    "print(f\"Severity sample: {sample.data['Severity'][:3]}\")\n",
    "print(f\"Distance sample: {sample.data['Distance(mi)'][:3]}\")\n",
    "\n",
    "# Convert to string\n",
    "converted = sample.convert_column_type(\"Severity\", str)\n",
    "print(\"\\nAfter converting Severity to string:\")\n",
    "print(converted.data[\"Severity\"][:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b35b76de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before rounding:\n",
      "[0.68, 2.5, 0.0]\n",
      "\n",
      "After rounding to 1 decimal:\n",
      "[0.7, 2.5, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Round column\n",
    "sample = state_year.head(10).select([\"State\", \"avg_distance\"])\n",
    "print(\"Before rounding:\")\n",
    "print(sample.data[\"avg_distance\"][:3])\n",
    "\n",
    "rounded = sample.round_column(\"avg_distance\", decimals=1)\n",
    "print(\"\\nAfter rounding to 1 decimal:\")\n",
    "print(rounded.data[\"avg_distance\"][:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d1b30af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count per state (first 5):\n",
      "State | count\n",
      "------+------\n",
      "AL    | 28   \n",
      "AR    | 25   \n",
      "AZ    | 29   \n",
      "CA    | 35   \n",
      "CO    | 29   \n",
      "\n",
      "[5 rows x 2 columns]\n",
      "\n",
      "Sum of accidents per state (first 5):\n",
      "State | total_accidents\n",
      "------+----------------\n",
      "AL    | 95816          \n",
      "AR    | 18385          \n",
      "AZ    | 153989         \n",
      "CA    | 1786142        \n",
      "CO    | 82828          \n",
      "\n",
      "[5 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# GroupBy convenience methods (count, sum, mean, min, max)\n",
    "grouped = state_year.groupby(\"State\")\n",
    "\n",
    "# Count\n",
    "count_result = grouped.count()\n",
    "print(\"Count per state (first 5):\")\n",
    "print(count_result.head(5))\n",
    "\n",
    "# Sum\n",
    "sum_result = grouped.sum(\"total_accidents\")\n",
    "print(\"\\nSum of accidents per state (first 5):\")\n",
    "print(sum_result.head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM Project (venv)",
   "language": "python",
   "name": "dm-project-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
